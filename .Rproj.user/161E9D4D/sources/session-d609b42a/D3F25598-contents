---
title: "Monte Carlo Simulation Experiment"
format: pdf
editor: visual
prefer-html: true
---

## Luke Catalano - Stat 155

# Scientific / Statistical Question

I am exploring whether or not it is possible to create meaningful groupings of coffee consumers through online survey data. I am looking to explore the limitations of the Proximus clustering algorithm through a controlled Monte Carlo simulation experiment. Proximus takes logical matrices as input, and produces clusters assignments for each individual observation, with the quality of the data greatly affecting the output of the algorithm.

In real-world settings, two majors issues with business data is sample size and the quality of the data. Following a factorial experimental design, I will explore how sample size and logical matrix sparsity affect the output of the Proximus clustering algorithm.

# Data

-   I will be generating new data based on the historic distribution of each column, with a normalized error, for each instance of a factor-level simulation. I will end up with 90 randomly generated, similar data to the current survey results, each with different amount of observations or sparistiy depending on the factor-level specification.

# Estimates

-   Jaccard similarity of the total approximation is provided for each proximus output, and I will be comparing the mean and standard deviation of the Jaccard similarity for each factor-level.
-   The Jaccard similarity of the total approximation is defined as the sum of a procedure done to each column pair in a matrix. The procedure is as follows: The size of the intersection of the columns divided by the size of the union of the columns, ranging from 0 (no similarity) to 1 (identical columns).

# Methods

I will be evaluating the performance of the Proximus algorithm from the Clustering for Business Analytics R package by Christian Buchta. I will be exploring how this algorithm handles data matrices with a differing number of observations, and how logical matrix sparsity effects the cluster output.

# Performance Criteria

-   The algorithm will produce the Jaccard similarity of the total approximation for each of the 90 instances of a simulation. A value of 1 indicates that the 0's and 1's of the original logical matrix were perfectly preserved (i.e. unchanged from the original). When parameters that affect algorithmic performance are changed, I am expecting to see shifts in this parameter as the algorithm begins to perform worse.

# Simulation Plan

### Differences from Project III:

\- Project III Utilized Grower/PAM clustering to attempt to group consumers based on their reported survey responses, however we were unable to uncover well defined clusters, which made it difficult to group individuals based on their responses. For Project IV, I will be using the Proximus clustering algorithm, and have converted survey responses into a logical matrix.

### Simulation:

-   Our two factors are the number of observations, and the logical matrix sparsity. Each simulation will use a different combination of factor-levels, leading to 9 factor-level simulations total.

-   Each factor-level simulation will have 10 simulations with randomly generated data following the factor-level parameters (low obs-low sparsity, low obs-medium sparsity, etc). This will lead to 90 simulations total.

-   The Factors will have the following levels:

    -   Number of Observations: low (500), medium (1500), high (2790)

    -   Logical Matrix Sparsity: low (1 columns with 90% sparsity), medium (3 columns with 90% sparsity), high (6 columns with 90% sparsity).

-   The Proximus model output will be created and stored for each factor level, for each of the simulations. As a result we will have 90 Proximus algorithm outputs, with 10 per factor-level combination.

# **Anticipated Challenges or Limitations**

In the event that individual observations are too closely related due to observed similarities in the logical matrix, Proximus will likely perform poorly in all 9 factor-level simulations. This is because there would be an extreme lack of differences in the "distance" between each observation, preventing unique clusters to be formed. In this case, Proximus would not be the best fit for our data, and we would likely see little to no difference between each output.

## Experiment

```{r}
#Preprocess & Load Data:
source("functions/preprocess.R")
library(cba)
library(dplyr)
library(cluster)
set.seed(2)

#Columns selected for clustering (categorical only)
vars <- c(
  "where_drink", #Where do you drink coffee?
  "number_children", #How many children do you have?
  "brew", #Favorite brew?
  "additions", #Favorite addition to your coffee?
  "style", #Favoriate coffee style?
  "roast_level", #Preffered roast level?
  "caffeine", #How much caffine do you like in your coffe?
  "expertise", #How would you rate your own coffee expertise?
  "why_drink", #Why do you drink coffee?
  "taste", #Do you like the taste of coffee?
  "know_source", #Do you know where your coffee is sourced from?
  "value_cafe", #Do you feel cafe coffee is good value?
  "gender", #What is your gender?
  "education_level", #What is your education level?
  "employment_status",#What is your employment status?
  'most_paid', #What is the most you've ever paid for a cup of coffee?
  'ethnicity_race', #What is your ethnicity/race
  'spent_equipment', #how much spent on coffee equipment in the past 5 years?
  "wfh", #Do you work from home?
  'cups', #How many cups of coffee do you typically drink a day?
  'age', #What is your age?
  "total_spend", #how much do you typically spend on coffee in a month?
  'favorite' # What is your favorite coffee drink?
)

#Subset and clean data
coffee <- coffee_survey[, vars]
coffee_clean <- na.omit(coffee)

#Ensure all variables are factors
coffee_clean[] <- lapply(coffee_clean, function(x) {
  if (is.character(x)) as.factor(x) else x
})
```

```{r}
# Build logical matrix from clean data
coffee_bool <- data.frame(
  children = coffee_clean$number_children,
  gender = coffee_clean$gender,
  additions = coffee_clean$additions,
  wfh = coffee_clean$wfh,
  cups = coffee_clean$cups,
  know_source = coffee_clean$know_source
)

# Conversion function: clean and binarize columns
conversion <- function(df, column, logic, val){
  if (logic == 'Equal') {
    df[[column]] <- ifelse(df[[column]] == val, 0, 1)
  }
  df[[column]] <- as.numeric(df[[column]])
  cat("Success, the proportion of True is:", mean(df[[column]]), "\n")
  return(df)
}

# Apply binary transformations
coffee_bool <- conversion(coffee_bool, 'additions', 'Equal', 'No - just black')
coffee_bool <- conversion(coffee_bool, 'children', 'Equal', 'None')
coffee_bool <- conversion(coffee_bool, 'gender', 'Equal', 'Male')
coffee_bool <- conversion(coffee_bool, 'wfh', 'Equal', 'I primarily work from home')
coffee_bool <- conversion(coffee_bool, 'know_source', 'Equal', 'Yes')

# Process cups: convert to numeric before comparison
coffee_bool$cups[coffee_bool$cups == 'More than 4'] <- 5
coffee_bool$cups[coffee_bool$cups == 'Less than 1'] <- 0
coffee_bool$cups <- as.numeric(coffee_bool$cups)
coffee_bool$cups <- ifelse(coffee_bool$cups >= 2, 1, 0)

# logic
coffee_logical <- coffee_bool == 1

# Run Proximus
model <- proximus(coffee_logical, max.radius = 2, min.size = 1, min.retry = 10, max.iter = 16, debug = FALSE)

summary <- summary(model)

summary$jsim 
```

```{r}
library(cba)

# Factors
obs_levels <- c(500, 1500, 2970)
sparse_levels <- c(1, 3, 6)

# Sparsify
sparsify <- function(matrix, num_cols, target = 0.65) {
  cols <- sample(ncol(matrix), min(num_cols, ncol(matrix)))
  for (j in cols) {
    ones <- which(matrix[, j])
    to_zero <- sample(ones, size = max(0, length(ones) - round((1 - target) * nrow(matrix))))
    matrix[to_zero, j] <- FALSE
  }
  matrix
}

# Loop: run and extract printed Jsim
for (obs in obs_levels) {
  for (sparse in sparse_levels) {
    matrix <- coffee_logical[sample(nrow(coffee_logical), obs), 1:4]
    matrix <- sparsify(matrix, sparse)
    storage.mode(matrix) <- "logical"

    model <- proximus(matrix)
    summary_lines <- capture.output(summary(model))
    jsim_line <- grep("total  Jsim", summary_lines, value = TRUE)
    jsim_value <- as.numeric(sub(".*Jsim: ", "", jsim_line))

    cat("Obs =", obs, "| Sparse =", sparse, "| Jsim =", jsim_value, "\n")
  }
}
```

```{r}
library(cba)

# Factors

obs_levels <- c(500, 1500, 2970)
sparse_levels <- c(1, 3, 6)

# Sparsify function

sparsify <- function(matrix, num_cols, target = 0.65) {
  cols <- sample(ncol(matrix), min(num_cols, ncol(matrix)))
  for (j in cols) {
    ones <- which(matrix[, j])
    to_zero <- sample(ones, size = max(0, length(ones) - round((1 - target) * nrow(matrix))))
    matrix[to_zero, j] <- FALSE
  }
  matrix
}

# Initialize results table
results <- data.frame(Obs = integer(), Sparse = integer(), Rep = integer(), Jsim = numeric())

# 10 reps for each factor-level
for (obs in obs_levels) {
  for (sparse in sparse_levels) {
    for (rep in 1:10) {
      matrix <- coffee_logical[sample(nrow(coffee_logical), obs), 1:4]
      matrix <- sparsify(matrix, sparse)
      storage.mode(matrix) <- "logical"

      model <- proximus(matrix)
      summary_lines <- capture.output(summary(model))
      jsim_line <- grep("total  Jsim", summary_lines, value = TRUE)
      jsim_value <- as.numeric(sub(".*Jsim: ", "", jsim_line))

      results <- rbind(results, data.frame(
        Obs = obs,
        Sparse = sparse,
        Rep = rep,
        Jsim = jsim_value
      ))
    }
  }
}

# View or export the results table
print(results)
```
